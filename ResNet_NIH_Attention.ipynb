{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as cp\n",
    "from collections import OrderedDict\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torch import Tensor\n",
    "from typing import Any, List, Tuple\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "from skimage.measure import label\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla P100-PCIE-12GB'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('/home/parkar.s/NIH_multilabel_classification/Data_Entry_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>y]</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2682</td>\n",
       "      <td>2749</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>Cardiomegaly|Emphysema</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2894</td>\n",
       "      <td>2729</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>Cardiomegaly|Effusion</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.171</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2582</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index          Finding Labels  Follow-up #  Patient ID  \\\n",
       "0  00000001_000.png            Cardiomegaly            0           1   \n",
       "1  00000001_001.png  Cardiomegaly|Emphysema            1           1   \n",
       "2  00000001_002.png   Cardiomegaly|Effusion            2           1   \n",
       "3  00000002_000.png              No Finding            0           2   \n",
       "4  00000003_000.png                  Hernia            0           3   \n",
       "\n",
       "   Patient Age Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
       "0           58              M            PA                 2682     2749   \n",
       "1           58              M            PA                 2894     2729   \n",
       "2           58              M            PA                 2500     2048   \n",
       "3           81              M            PA                 2500     2048   \n",
       "4           81              F            PA                 2582     2991   \n",
       "\n",
       "   OriginalImagePixelSpacing[x     y]  Unnamed: 11  \n",
       "0                        0.143  0.143          NaN  \n",
       "1                        0.143  0.143          NaN  \n",
       "2                        0.168  0.168          NaN  \n",
       "3                        0.171  0.171          NaN  \n",
       "4                        0.143  0.143          NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PA    67310\n",
       "AP    44810\n",
       "Name: View Position, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['View Position'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 14\n",
    "CLASS_NAMES = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "                'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/scratch/parkar.s/NIH/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = []\n",
    "targets = []\n",
    "with open('/home/parkar.s/NIH_multilabel_classification/NIH_labels/train_list.txt') as fp:\n",
    "    for line in fp:\n",
    "        file, target = line.split(' ',1)\n",
    "        a = os.path.join(file_path,file)\n",
    "        train_list.append(a)\n",
    "        targets.append([int(i) for i in target.strip().split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/scratch/parkar.s/NIH/images/00023313_004.png',\n",
       " [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list[5], targets[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path,\n",
    "        image_paths = [],\n",
    "        targets = [],\n",
    "        resize = None,\n",
    "        augmentations=None,\n",
    "        backend=\"cv2\",\n",
    "        channel_first= True\n",
    "\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param image_paths: list of paths to images\n",
    "        :param targets: numpy array\n",
    "        :param resize: tuple or None\n",
    "        :param augmentations: albumentations augmentations\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.resize = resize\n",
    "        self.augmentations = augmentations\n",
    "        self.backend = backend\n",
    "        self.channel_first = channel_first\n",
    "        \n",
    "        self.image_paths = []\n",
    "        self.targets = []\n",
    "        with open(data_path) as fp:\n",
    "            for line in fp:\n",
    "                file, target = line.split(' ',1)\n",
    "                a = os.path.join(file_path,file)\n",
    "                self.image_paths.append(a)\n",
    "                self.targets.append([int(i) for i in target.strip().split()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        targets = self.targets[item]\n",
    "        \n",
    "        if self.backend == \"cv2\":\n",
    "            \n",
    "            #Load the image\n",
    "            image = cv2.imread(self.image_paths[item],1)\n",
    "            \n",
    "            #Resize\n",
    "            if self.resize is not None:\n",
    "                image = cv2.resize(\n",
    "                    image,\n",
    "                    (self.resize[1], self.resize[0]),\n",
    "                    interpolation=cv2.INTER_CUBIC,\n",
    "                )\n",
    "            \n",
    "            if self.augmentations is not None:\n",
    "                augmented = self.augmentations(image=image)\n",
    "                image = augmented[\"image\"]\n",
    "        \n",
    "        else:\n",
    "            raise Exception(\"Backend not implemented\")\n",
    "        \n",
    "        # converting to pytorch image format & 2,0,1 because pytorch excepts image channel first then dimension of image\n",
    "        if self.channel_first:\n",
    "            image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        \n",
    "        # finally returning image tensor and its image id\n",
    "        return {\n",
    "            \"image\": torch.tensor(image),\n",
    "            \"targets\": torch.tensor(targets),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "LR_G = 1e-8\n",
    "LR_L = 1e-8\n",
    "LR_F = 1e-3\n",
    "num_epochs = 50\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "\n",
    "FLAGS = {\n",
    "    'fold': 0,\n",
    "    'model': 'resnet152d',\n",
    "    'pretrained': True,\n",
    "    'batch_size': 4,\n",
    "    'num_workers': 4,\n",
    "    'lr': 3e-4,\n",
    "    'epochs': 10,\n",
    "    'beta1': 0.9,\n",
    "    'beta2': 0.999,\n",
    "    'cuda': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug = albumentations.Compose(\n",
    "    [       albumentations.Resize(224, 224),\n",
    "            albumentations.CenterCrop(224, 224),\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "                max_pixel_value=255.0,\n",
    "                p=1.0,\n",
    "            )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/parkar.s/NIH_multilabel_classification/NIH_labels/train_list.txt'\n",
    "\n",
    "train_dataset = ImageDataset(\n",
    "    data_path = train_path,\n",
    "    resize= None,\n",
    "    augmentations= train_aug,\n",
    ")\n",
    "\n",
    "\n",
    "'''\n",
    "The drop_last=True parameter ignores the last batch \n",
    "(when the number of examples in your dataset is not divisible by your batch_size) \n",
    "while drop_last=False will make the last batch smaller than your batch_size \n",
    "'''\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE,\n",
    "                         shuffle=True, num_workers=4, pin_memory=True, drop_last = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4904"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = '/home/parkar.s/NIH_multilabel_classification/NIH_labels/val_list.txt'\n",
    "\n",
    "valid_dataset = ImageDataset(\n",
    "    data_path = val_path,\n",
    "    resize= None,\n",
    "    augmentations= train_aug,\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE,\n",
    "                         shuffle=True, num_workers=4, pin_memory=True, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "701"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_loader.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img_dict):\n",
    "    image_tensor = img_dict[\"image\"]\n",
    "    target = img_dict[\"targets\"]\n",
    "    print(target)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    image = image_tensor.permute(1, 2, 0)\n",
    "    \n",
    "    '''\n",
    "    Loading an RGB image will result in an image consisting of integer values\n",
    "    Converting into tensor will convert them into float. Now when you try to display such an image, you ll get the following error-\n",
    "    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
    "    \n",
    "    So we first need to convert it back to uint8\n",
    "    '''\n",
    "    \n",
    "    plt.imshow(image.numpy().astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_AUCs(gt, pred):\n",
    "    \"\"\"Computes Area Under the Curve (AUC) from prediction scores.\n",
    "    Args:\n",
    "        gt: Pytorch tensor on GPU, shape = [n_samples, n_classes]\n",
    "          true binary labels.\n",
    "        pred: Pytorch tensor on GPU, shape = [n_samples, n_classes]\n",
    "          can either be probability estimates of the positive class,\n",
    "          confidence values, or binary decisions.\n",
    "    Returns:\n",
    "        List of AUROCs of all classes.\n",
    "    \"\"\"\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Attention_gen_patchs(ori_image, fm_cuda):\n",
    "    # feature map -> feature mask (using feature map to crop on the original image) -> crop -> patchs\n",
    "    feature_conv = fm_cuda.data.cpu().numpy()\n",
    "    size_upsample = (224, 224) \n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "\n",
    "    patchs_cuda = torch.FloatTensor().cuda()\n",
    "\n",
    "    for i in range(0, bz):\n",
    "        feature = feature_conv[i]\n",
    "        cam = feature.reshape((nc, h*w))\n",
    "        cam = cam.sum(axis=0)\n",
    "        cam = cam.reshape(h,w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "\n",
    "        heatmap_bin = binImage(cv2.resize(cam_img, size_upsample))\n",
    "        heatmap_maxconn = selectMaxConnect(heatmap_bin)\n",
    "        heatmap_mask = heatmap_bin * heatmap_maxconn\n",
    "\n",
    "        ind = np.argwhere(heatmap_mask != 0)\n",
    "        minh = min(ind[:,0])\n",
    "        minw = min(ind[:,1])\n",
    "        maxh = max(ind[:,0])\n",
    "        maxw = max(ind[:,1])\n",
    "        \n",
    "        # to ori image \n",
    "        image = ori_image[i].numpy().reshape(224,224,3)\n",
    "        image = image[int(224*0.334):int(224*0.667),int(224*0.334):int(224*0.667),:]\n",
    "\n",
    "        image = cv2.resize(image, size_upsample)\n",
    "        image_crop = image[minh:maxh,minw:maxw,:] * 256 # because image was normalized before\n",
    "        image_crop = preprocess(Image.fromarray(image_crop.astype('uint8')).convert('RGB')) \n",
    "\n",
    "        img_variable = torch.autograd.Variable(image_crop.reshape(3,224,224).unsqueeze(0).cuda())\n",
    "\n",
    "        patchs_cuda = torch.cat((patchs_cuda,img_variable),0)\n",
    "\n",
    "    return patchs_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binImage(heatmap):\n",
    "    _, heatmap_bin = cv2.threshold(heatmap , 0 , 255 , cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    # t in the paper\n",
    "    #_, heatmap_bin = cv2.threshold(heatmap , 178 , 255 , cv2.THRESH_BINARY)\n",
    "    return heatmap_bin\n",
    "\n",
    "\n",
    "def selectMaxConnect(heatmap):\n",
    "    labeled_img, num = label(heatmap, connectivity=2, background=0, return_num=True)    \n",
    "    max_label = 0\n",
    "    max_num = 0\n",
    "    for i in range(1, num+1):\n",
    "        if np.sum(labeled_img == i) > max_num:\n",
    "            max_num = np.sum(labeled_img == i)\n",
    "            max_label = i\n",
    "    lcc = (labeled_img == max_label)\n",
    "    if max_num == 0:\n",
    "        lcc = (labeled_img == -1)\n",
    "    lcc = lcc + 0\n",
    "    return lcc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Resize((256,256)),\n",
    "   transforms.CenterCrop(224),\n",
    "   transforms.ToTensor(),\n",
    "   normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Only Resnet (Pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and eval loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') #device, will be different for each core on the TPU\n",
    "epochs = FLAGS['epochs']\n",
    "fold = FLAGS['fold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_fn(data_loader, loss_fn, model, optimizer, device, scheduler, epoch):\n",
    "    model.train() # put model in training mode\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    for index, d in enumerate(data_loader): # enumerate through the dataloader\n",
    "        \n",
    "        images = d['image'] # obtain the ids\n",
    "        targets = d['targets'] # obtain the target\n",
    "        if FLAGS['cuda']:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "        # pass image to model\n",
    "        \n",
    "        # clear out the accumulated gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # make predictions\n",
    "        outputs = model(images)\n",
    "        \n",
    "        targets = targets.to(torch.float32)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        if (index%500) == 0: \n",
    "            print('step: {} totalloss: {loss:.3f} '.format(index, loss = loss))\n",
    "\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        # Performs parameter update\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        running_loss += loss.data.item()\n",
    "\n",
    "\n",
    "\n",
    "        # Step the scheduler\n",
    "        if scheduler is not None: \n",
    "            scheduler.step()\n",
    "            \n",
    "    epoch_loss = float(running_loss) / float(index)\n",
    "    print(' Epoch over  Loss: {:.5f}'.format(epoch_loss))\n",
    "\n",
    "     # put model in eval mode for later use\n",
    "    \n",
    "def eval_loop_fn(data_loader, loss_fn, model, device):\n",
    "    \n",
    "    #will notify all your layers that you are in eval mode,\n",
    "    #that way, batchnorm or dropout layers will work in eval\n",
    "    #mode instead of training mode.\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "    for bi, d in enumerate(data_loader): # enumerate through dataloader\n",
    "        \n",
    "        images = d['image'] # obtain the ids\n",
    "        targets = d['targets']# # obtain the targets\n",
    "        \n",
    "        if FLAGS['cuda']:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            \n",
    "\n",
    "        # pass image to model\n",
    "        \n",
    "        # no_grad impacts the autograd engine and deactivate it.\n",
    "        # It will reduce memory usage and speed up computations\n",
    "        # but you won’t be able to backprop\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            outputs = model(images)\n",
    "\n",
    "        # Add the outputs and targets to a list \n",
    "        targets_np = targets.cpu().detach().numpy().tolist()\n",
    "        outputs_np = outputs.cpu().detach().numpy().tolist()\n",
    "        fin_targets.extend(targets_np)\n",
    "        fin_outputs.extend(outputs_np)    \n",
    "        del targets_np, outputs_np\n",
    "        gc.collect() # delete for memory conservation\n",
    "                \n",
    "    o,t = np.array(fin_outputs), np.array(fin_targets)\n",
    "    \n",
    "\n",
    "    \n",
    "    # calculate loss\n",
    "    # loss = loss_fn(torch.tensor(o), t)\n",
    "    \n",
    "    AUROCs_g = compute_AUCs(torch.tensor(t), torch.tensor(o))\n",
    "    AUROC_avg = np.array(AUROCs_g).mean()\n",
    "    print('Global branch: The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "    for i in range(N_CLASSES):\n",
    "        print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs_g[i]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Ross Wightman's timm package\n",
    "class TimmModels(nn.Module):\n",
    "    def __init__(self, model_name,pretrained=True, num_classes=3):\n",
    "        super(TimmModels, self).__init__()\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.classifier = nn.Linear(2048, num_classes)\n",
    "\n",
    "        self.m = timm.create_model(model_name,pretrained=pretrained)\n",
    "        model_list = list(self.m.children())\n",
    "        model_list = model_list[:-2]\n",
    "        model_list[-1][-1].act3 = nn.Identity()\n",
    "        self.m = nn.Sequential(*model_list)\n",
    "        \n",
    "    def forward(self, image):\n",
    "        features = self.m(image)\n",
    "        out = F.relu(features, inplace=True)\n",
    "        out_after_pooling = F.avg_pool2d(out, kernel_size=7, stride=1).view(features.size(0), -1)\n",
    "        out = self.classifier(out_after_pooling)\n",
    "        out = self.Sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fusion_Branch(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Fusion_Branch, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, global_pool, local_pool):\n",
    "        #fusion = torch.cat((global_pool.unsqueeze(2), local_pool.unsqueeze(2)), 2).cuda()\n",
    "        #fusion = fusion.max(2)[0]#.squeeze(2).cuda()\n",
    "        #print(fusion.shape)\n",
    "        fusion = torch.cat((global_pool,local_pool), 1).cuda()\n",
    "        fusion_var = torch.autograd.Variable(fusion)\n",
    "        x = self.fc(fusion_var)\n",
    "        x = self.Sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "MX = TimmModels(FLAGS['model'],pretrained=FLAGS['pretrained'], num_classes=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-982588e14d82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# put model onto the current GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# often a good idea to scale the learning rate by number of cores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCosineAnnealingLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#let's use a scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MX' is not defined"
     ]
    }
   ],
   "source": [
    "model = MX.to(device) # put model onto the current GPU\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = Adam(model.parameters(), lr=FLAGS['lr']) # often a good idea to scale the learning rate by number of cores\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader)*FLAGS['epochs']) #let's use a scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'========== training fold {FLAGS[\"fold\"]} for {FLAGS[\"epochs\"]} epochs ==========')\n",
    "for i in range(2):\n",
    "    print(f'EPOCH {i}:')\n",
    "    # train one epoch\n",
    "    train_loop_fn(train_loader, loss_fn, model, optimizer, device, scheduler, i)\n",
    "\n",
    "    # validation one epoch\n",
    "    eval_loop_fn(valid_loader, loss_fn, model, device)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "print('Saving model...')\n",
    "\n",
    "torch.save(model.state_dict(), f'resnet_NIH_{FLAGS[\"epochs\"]}_epochs_pretrained.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '/home/parkar.s/NIH_multilabel_classification/NIH_labels/test_list.txt'\n",
    "\n",
    "test_dataset = ImageDataset(\n",
    "    data_path = test_path,\n",
    "    resize= None,\n",
    "    augmentations= train_aug,\n",
    ")\n",
    "\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE,\n",
    "                         shuffle=True, num_workers=4, pin_memory=True, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "MX_test = TimmModels(FLAGS['model'],pretrained=FLAGS['pretrained'], num_classes=14)\n",
    "model_test = MX_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'resnet_NIH_10_epochs_pretrained.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global branch: The average AUROC is 0.831\n",
      "The AUROC of Atelectasis is 0.8146734892948528\n",
      "The AUROC of Cardiomegaly is 0.907767266665094\n",
      "The AUROC of Effusion is 0.8788024915771728\n",
      "The AUROC of Infiltration is 0.7049163282638219\n",
      "The AUROC of Mass is 0.8338879825915774\n",
      "The AUROC of Nodule is 0.768601744856423\n",
      "The AUROC of Pneumonia is 0.7596380247226246\n",
      "The AUROC of Pneumothorax is 0.863845226467845\n",
      "The AUROC of Consolidation is 0.7939528478960858\n",
      "The AUROC of Edema is 0.8908690128611136\n",
      "The AUROC of Emphysema is 0.9247012695891238\n",
      "The AUROC of Fibrosis is 0.8347302780955623\n",
      "The AUROC of Pleural_Thickening is 0.7795339818358678\n",
      "The AUROC of Hernia is 0.8815617090963228\n"
     ]
    }
   ],
   "source": [
    "eval_loop_fn(test_loader, loss_fn, model_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Hamming score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testImageDataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path,\n",
    "        image_paths = [],\n",
    "        targets = [],\n",
    "        resize = None,\n",
    "        augmentations=None,\n",
    "        backend=\"cv2\",\n",
    "        channel_first= True\n",
    "\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param image_paths: list of paths to images\n",
    "        :param targets: numpy array\n",
    "        :param resize: tuple or None\n",
    "        :param augmentations: albumentations augmentations\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.resize = resize\n",
    "        self.augmentations = augmentations\n",
    "        self.backend = backend\n",
    "        self.channel_first = channel_first\n",
    "        \n",
    "        self.image_paths = []\n",
    "        self.targets = []\n",
    "        with open(data_path) as fp:\n",
    "            for line in fp:\n",
    "                file, target = line.split(' ',1)\n",
    "                a = os.path.join(file_path,file)\n",
    "                self.image_paths.append(a)\n",
    "                self.targets.append([int(i) for i in target.strip().split()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        targets = self.targets[item]\n",
    "        \n",
    "        if self.backend == \"cv2\":\n",
    "            \n",
    "            #Load the image\n",
    "            image = cv2.imread(self.image_paths[item],1)\n",
    "            \n",
    "            #Resize\n",
    "            if self.resize is not None:\n",
    "                image = cv2.resize(\n",
    "                    image,\n",
    "                    (self.resize[1], self.resize[0]),\n",
    "                    interpolation=cv2.INTER_CUBIC,\n",
    "                )\n",
    "            \n",
    "            if self.augmentations is not None:\n",
    "                augmented = self.augmentations(image=image)\n",
    "                image = augmented[\"image\"]\n",
    "        \n",
    "        else:\n",
    "            raise Exception(\"Backend not implemented\")\n",
    "        \n",
    "        # converting to pytorch image format & 2,0,1 because pytorch excepts image channel first then dimension of image\n",
    "        if self.channel_first:\n",
    "            image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        \n",
    "        # finally returning image tensor and its image id\n",
    "        return {\n",
    "            \"image\": torch.tensor(image),\n",
    "            \"targets\": torch.tensor(targets),\n",
    "            \"filename\": self.image_paths[item]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '/home/parkar.s/NIH_multilabel_classification/NIH_labels/test_list.txt'\n",
    "\n",
    "test_dataset = testImageDataset(\n",
    "    data_path = test_path,\n",
    "    resize= None,\n",
    "    augmentations= train_aug,\n",
    ")\n",
    "\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE,\n",
    "                         shuffle=True, num_workers=4, pin_memory=True, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': tensor([[[-1.6555, -1.9809, -2.0494,  ..., -1.2788, -0.9020, -0.0458],\n",
       "          [-1.7240, -1.9980, -2.0494,  ..., -1.9809, -1.8439, -1.3644],\n",
       "          [-1.7240, -1.9980, -2.0494,  ..., -2.0665, -2.0494, -1.9467],\n",
       "          ...,\n",
       "          [-2.1008, -2.1008, -2.1179,  ..., -1.9809, -1.2617, -0.0458],\n",
       "          [-2.1008, -2.1008, -2.1179,  ..., -1.9638, -1.2103,  0.0227],\n",
       "          [-2.1008, -2.1008, -2.1179,  ..., -1.9638, -1.1760,  0.0569]],\n",
       " \n",
       "         [[-1.5630, -1.8957, -1.9657,  ..., -1.1779, -0.7927,  0.0826],\n",
       "          [-1.6331, -1.9132, -1.9657,  ..., -1.8957, -1.7556, -1.2654],\n",
       "          [-1.6331, -1.9132, -1.9657,  ..., -1.9832, -1.9657, -1.8606],\n",
       "          ...,\n",
       "          [-2.0182, -2.0182, -2.0357,  ..., -1.8957, -1.1604,  0.0826],\n",
       "          [-2.0182, -2.0182, -2.0357,  ..., -1.8782, -1.1078,  0.1527],\n",
       "          [-2.0182, -2.0182, -2.0357,  ..., -1.8782, -1.0728,  0.1877]],\n",
       " \n",
       "         [[-1.3339, -1.6650, -1.7347,  ..., -0.9504, -0.5670,  0.3045],\n",
       "          [-1.4036, -1.6824, -1.7347,  ..., -1.6650, -1.5256, -1.0376],\n",
       "          [-1.4036, -1.6824, -1.7347,  ..., -1.7522, -1.7347, -1.6302],\n",
       "          ...,\n",
       "          [-1.7870, -1.7870, -1.8044,  ..., -1.6650, -0.9330,  0.3045],\n",
       "          [-1.7870, -1.7870, -1.8044,  ..., -1.6476, -0.8807,  0.3742],\n",
       "          [-1.7870, -1.7870, -1.8044,  ..., -1.6476, -0.8458,  0.4091]]]),\n",
       " 'targets': tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'filename': '/scratch/parkar.s/NIH/images/00020904_001.png'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_hamming(data_loader, loss_fn, model, device):\n",
    "    \n",
    "    #will notify all your layers that you are in eval mode,\n",
    "    #that way, batchnorm or dropout layers will work in eval\n",
    "    #mode instead of training mode.\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "    fin_filenames = []\n",
    "    for bi, d in enumerate(data_loader): # enumerate through dataloader\n",
    "        \n",
    "        images = d['image'] # obtain the ids\n",
    "        targets = d['targets']# # obtain the targets\n",
    "        filenames = d['filename']\n",
    "        \n",
    "        if FLAGS['cuda']:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            \n",
    "\n",
    "        # pass image to model\n",
    "        \n",
    "        # no_grad impacts the autograd engine and deactivate it.\n",
    "        # It will reduce memory usage and speed up computations\n",
    "        # but you won’t be able to backprop\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            outputs = model(images)\n",
    "\n",
    "        # Add the outputs and targets to a list \n",
    "        targets_np = targets.cpu().detach().numpy().tolist()\n",
    "        outputs_np = outputs.cpu().detach().numpy().tolist()\n",
    "        fin_targets.extend(targets_np)\n",
    "        fin_outputs.extend(outputs_np)\n",
    "        fin_filenames.extend(filenames)\n",
    "        del targets_np, outputs_np\n",
    "        gc.collect() # delete for memory conservation\n",
    "                \n",
    "    o,t = np.array(fin_outputs), np.array(fin_targets)\n",
    "    f = fin_filenames\n",
    "    \n",
    "    return o,t,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "MX_test = TimmModels(FLAGS['model'],pretrained=FLAGS['pretrained'], num_classes=14)\n",
    "model_test = MX_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'resnet_NIH_10_epochs_pretrained.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "o,t,f = eval_hamming(test_loader, loss_fn, model_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[3], preds[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in o:\n",
    "    a = np.where(i>0.3, 1, 0)\n",
    "    preds.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "hamming_losses = []\n",
    "for i in range(len(o)):\n",
    "    hamming_losses.append(hamming_loss(t[i], preds[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    '''\n",
    "    Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
    "    http://stackoverflow.com/q/32239577/395857\n",
    "    '''\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set( np.where(y_true[i])[0] )\n",
    "        set_pred = set( np.where(y_pred[i])[0] )\n",
    "        #print('\\nset_true: {0}'.format(set_true))\n",
    "        #print('set_pred: {0}'.format(set_pred))\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
    "                    float( len(set_true.union(set_pred)) )\n",
    "        #print('tmp_a: {0}'.format(tmp_a))\n",
    "        acc_list.append(tmp_a)\n",
    "    return np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "hamming_scores = []\n",
    "for i in range(len(o)):\n",
    "    hamming_scores.append(hamming_score(t[i], preds[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Filename\": f, \"Hamming_Score\": hamming_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Hamming_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00008186_000.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00026794_000.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00015405_000.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00016086_000.png</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00025695_026.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00009145_000.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00026336_003.png</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00025869_000.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00016080_000.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00015857_002.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00020624_005.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00013184_000.png</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00001278_020.png</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00010664_002.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00007617_000.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00000277_002.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00021939_010.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00001326_006.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00023065_020.png</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00005362_000.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00005278_000.png</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00020624_011.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00020811_002.png</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00001498_001.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00026555_004.png</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00018360_029.png</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00027415_022.png</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00006808_037.png</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00018560_001.png</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00008830_003.png</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22402</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00000372_015.png</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22403</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00007076_015.png</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22404</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00023128_025.png</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22405</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00023068_031.png</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22406</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00009144_003.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22407</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00004534_008.png</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22408</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00020341_000.png</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22409</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00010007_167.png</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22410</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00015442_033.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22411</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00014135_000.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22412</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00027415_065.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22413</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00005201_007.png</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22414</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00022572_073.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22415</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00005425_000.png</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22416</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00016614_000.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22417</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00000099_012.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22418</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00015275_018.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22419</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00023085_000.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22420</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00019150_005.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22421</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00019158_004.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22422</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00009137_002.png</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22423</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00015982_003.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22424</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00012710_000.png</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22425</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00018019_018.png</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22426</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00009138_013.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22427</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00005681_031.png</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22428</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00013279_000.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22429</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00030162_019.png</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22430</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00026078_006.png</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22431</th>\n",
       "      <td>/scratch/parkar.s/NIH/images/00026050_011.png</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22432 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filename  Hamming_Score\n",
       "0      /scratch/parkar.s/NIH/images/00008186_000.png       1.000000\n",
       "1      /scratch/parkar.s/NIH/images/00026794_000.png       1.000000\n",
       "2      /scratch/parkar.s/NIH/images/00015405_000.png       1.000000\n",
       "3      /scratch/parkar.s/NIH/images/00016086_000.png       0.785714\n",
       "4      /scratch/parkar.s/NIH/images/00025695_026.png       1.000000\n",
       "5      /scratch/parkar.s/NIH/images/00009145_000.png       1.000000\n",
       "6      /scratch/parkar.s/NIH/images/00026336_003.png       0.785714\n",
       "7      /scratch/parkar.s/NIH/images/00025869_000.png       1.000000\n",
       "8      /scratch/parkar.s/NIH/images/00016080_000.png       1.000000\n",
       "9      /scratch/parkar.s/NIH/images/00015857_002.png       1.000000\n",
       "10     /scratch/parkar.s/NIH/images/00020624_005.png       1.000000\n",
       "11     /scratch/parkar.s/NIH/images/00013184_000.png       0.928571\n",
       "12     /scratch/parkar.s/NIH/images/00001278_020.png       0.928571\n",
       "13     /scratch/parkar.s/NIH/images/00010664_002.png       1.000000\n",
       "14     /scratch/parkar.s/NIH/images/00007617_000.png       1.000000\n",
       "15     /scratch/parkar.s/NIH/images/00000277_002.png       1.000000\n",
       "16     /scratch/parkar.s/NIH/images/00021939_010.png       1.000000\n",
       "17     /scratch/parkar.s/NIH/images/00001326_006.png       1.000000\n",
       "18     /scratch/parkar.s/NIH/images/00023065_020.png       0.928571\n",
       "19     /scratch/parkar.s/NIH/images/00005362_000.png       1.000000\n",
       "20     /scratch/parkar.s/NIH/images/00005278_000.png       0.928571\n",
       "21     /scratch/parkar.s/NIH/images/00020624_011.png       1.000000\n",
       "22     /scratch/parkar.s/NIH/images/00020811_002.png       0.928571\n",
       "23     /scratch/parkar.s/NIH/images/00001498_001.png       1.000000\n",
       "24     /scratch/parkar.s/NIH/images/00026555_004.png       0.785714\n",
       "25     /scratch/parkar.s/NIH/images/00018360_029.png       0.857143\n",
       "26     /scratch/parkar.s/NIH/images/00027415_022.png       0.785714\n",
       "27     /scratch/parkar.s/NIH/images/00006808_037.png       0.928571\n",
       "28     /scratch/parkar.s/NIH/images/00018560_001.png       0.928571\n",
       "29     /scratch/parkar.s/NIH/images/00008830_003.png       0.928571\n",
       "...                                              ...            ...\n",
       "22402  /scratch/parkar.s/NIH/images/00000372_015.png       0.928571\n",
       "22403  /scratch/parkar.s/NIH/images/00007076_015.png       0.928571\n",
       "22404  /scratch/parkar.s/NIH/images/00023128_025.png       0.857143\n",
       "22405  /scratch/parkar.s/NIH/images/00023068_031.png       0.928571\n",
       "22406  /scratch/parkar.s/NIH/images/00009144_003.png       1.000000\n",
       "22407  /scratch/parkar.s/NIH/images/00004534_008.png       0.857143\n",
       "22408  /scratch/parkar.s/NIH/images/00020341_000.png       0.857143\n",
       "22409  /scratch/parkar.s/NIH/images/00010007_167.png       0.857143\n",
       "22410  /scratch/parkar.s/NIH/images/00015442_033.png       1.000000\n",
       "22411  /scratch/parkar.s/NIH/images/00014135_000.png       1.000000\n",
       "22412  /scratch/parkar.s/NIH/images/00027415_065.png       1.000000\n",
       "22413  /scratch/parkar.s/NIH/images/00005201_007.png       0.785714\n",
       "22414  /scratch/parkar.s/NIH/images/00022572_073.png       1.000000\n",
       "22415  /scratch/parkar.s/NIH/images/00005425_000.png       0.928571\n",
       "22416  /scratch/parkar.s/NIH/images/00016614_000.png       1.000000\n",
       "22417  /scratch/parkar.s/NIH/images/00000099_012.png       1.000000\n",
       "22418  /scratch/parkar.s/NIH/images/00015275_018.png       1.000000\n",
       "22419  /scratch/parkar.s/NIH/images/00023085_000.png       1.000000\n",
       "22420  /scratch/parkar.s/NIH/images/00019150_005.png       1.000000\n",
       "22421  /scratch/parkar.s/NIH/images/00019158_004.png       1.000000\n",
       "22422  /scratch/parkar.s/NIH/images/00009137_002.png       0.928571\n",
       "22423  /scratch/parkar.s/NIH/images/00015982_003.png       1.000000\n",
       "22424  /scratch/parkar.s/NIH/images/00012710_000.png       0.928571\n",
       "22425  /scratch/parkar.s/NIH/images/00018019_018.png       0.928571\n",
       "22426  /scratch/parkar.s/NIH/images/00009138_013.png       1.000000\n",
       "22427  /scratch/parkar.s/NIH/images/00005681_031.png       0.857143\n",
       "22428  /scratch/parkar.s/NIH/images/00013279_000.png       1.000000\n",
       "22429  /scratch/parkar.s/NIH/images/00030162_019.png       1.000000\n",
       "22430  /scratch/parkar.s/NIH/images/00026078_006.png       0.928571\n",
       "22431  /scratch/parkar.s/NIH/images/00026050_011.png       0.928571\n",
       "\n",
       "[22432 rows x 2 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') #device, will be different for each core on the TPU\n",
    "epochs = FLAGS['epochs']\n",
    "fold = FLAGS['fold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = {\n",
    "    'fold': 0,\n",
    "    'model': 'resnet152d',\n",
    "    'pretrained': True,\n",
    "    'batch_size': 4,\n",
    "    'num_workers': 4,\n",
    "    'lr': 3e-7,\n",
    "    'lr_f': 1e-4,\n",
    "    'epochs': 10,\n",
    "    'beta1': 0.9,\n",
    "    'beta2': 0.999,\n",
    "    'cuda': True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Ross Wightman's timm package\n",
    "class TimmModels(nn.Module):\n",
    "    def __init__(self, model_name,pretrained=True, num_classes=3):\n",
    "        super(TimmModels, self).__init__()\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.classifier = nn.Linear(2048, num_classes)\n",
    "\n",
    "        self.m = timm.create_model(model_name,pretrained=pretrained)\n",
    "        model_list = list(self.m.children())\n",
    "        model_list = model_list[:-2]\n",
    "        model_list[-1][-1].act3 = nn.Identity()\n",
    "        self.m = nn.Sequential(*model_list)\n",
    "        \n",
    "    def forward(self, image):\n",
    "        features = self.m(image)\n",
    "        out = F.relu(features, inplace=True)\n",
    "        out_after_pooling = F.avg_pool2d(out, kernel_size=7, stride=1).view(features.size(0), -1)\n",
    "        out = self.classifier(out_after_pooling)\n",
    "        out = self.Sigmoid(out)\n",
    "        return out, features, out_after_pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fusion_Branch(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Fusion_Branch, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, global_pool, local_pool):\n",
    "        #fusion = torch.cat((global_pool.unsqueeze(2), local_pool.unsqueeze(2)), 2).cuda()\n",
    "        #fusion = fusion.max(2)[0]#.squeeze(2).cuda()\n",
    "        #print(fusion.shape)\n",
    "        fusion = torch.cat((global_pool,local_pool), 1).cuda()\n",
    "        fusion_var = torch.autograd.Variable(fusion)\n",
    "        x = self.fc(fusion_var)\n",
    "        x = self.Sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_attn(data_loader, loss_fn, Global_Branch_model,Local_Branch_model, Fusion_Branch_model, \n",
    "                    optimizer_global, optimizer_local, optimizer_fusion, \n",
    "                    lr_scheduler_global, lr_scheduler_local, lr_scheduler_fusion, device, epoch):\n",
    "    # put model in training mode\n",
    "    Global_Branch_model.train()  #set model to training mode\n",
    "    Local_Branch_model.train()\n",
    "    Fusion_Branch_model.train()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    for index, d in enumerate(data_loader): # enumerate through the dataloader\n",
    "        \n",
    "        images = d['image'] # obtain the ids\n",
    "        targets = d['targets'] # obtain the target\n",
    "        if FLAGS['cuda']:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "        # pass image to model\n",
    "        \n",
    "        # clear out the accumulated gradients\n",
    "        \n",
    "        optimizer_global.zero_grad()\n",
    "        optimizer_local.zero_grad()\n",
    "        optimizer_fusion.zero_grad()\n",
    "        \n",
    "        # make predictions\n",
    "\n",
    "        output_global, fm_global, pool_global = Global_Branch_model(images)\n",
    "        \n",
    "        patchs_var = Attention_gen_patchs(images.cpu(),fm_global)\n",
    "        \n",
    "        output_local, _, pool_local = Local_Branch_model(patchs_var)\n",
    "\n",
    "        output_fusion = Fusion_Branch_model(pool_global, pool_local)\n",
    "        \n",
    "        targets = targets.to(torch.float32)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss1 = loss_fn(output_global, targets)\n",
    "        loss2 = loss_fn(output_local, targets)\n",
    "        loss3 = loss_fn(output_fusion, targets)\n",
    "        \n",
    "        loss = loss1*0.8 + loss2*0.1 + loss3*0.1 \n",
    "\n",
    "        if (index%500) == 0: \n",
    "            print('step: {} totalloss: {loss:.3f} loss1: {loss1:.3f} loss2: {loss2:.3f} loss3: {loss3:.3f}'.format(index, loss = loss, loss1 = loss1, loss2 = loss2, loss3 = loss3))\n",
    "\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        # Performs parameter update\n",
    "        optimizer_global.step()  \n",
    "        optimizer_local.step()\n",
    "        optimizer_fusion.step()\n",
    "        \n",
    "        running_loss += loss.data.item()\n",
    "\n",
    "        # Step the scheduler\n",
    "        lr_scheduler_global.step()\n",
    "        lr_scheduler_local.step()\n",
    "        lr_scheduler_fusion.step()\n",
    "            \n",
    "    epoch_loss = float(running_loss) / float(index)\n",
    "    print(' Epoch over  Loss: {:.5f}'.format(epoch_loss))\n",
    "\n",
    "    \n",
    "     # put model in eval mode for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_with_attn(data_loader, loss_fn, model_global, model_local, model_fusion, device):\n",
    "    \n",
    "    #will notify all your layers that you are in eval mode,\n",
    "    #that way, batchnorm or dropout layers will work in eval\n",
    "    #mode instead of training mode.\n",
    "    \n",
    "    model_global.eval()\n",
    "    model_local.eval()\n",
    "    model_fusion.eval()\n",
    "    \n",
    "    fin_targets = []\n",
    "    global_outputs = []\n",
    "    local_outputs = []\n",
    "    fusion_outputs = []\n",
    "    \n",
    "    for bi, d in enumerate(data_loader): # enumerate through dataloader\n",
    "        \n",
    "        images = d['image'] # obtain the ids\n",
    "        targets = d['targets']# # obtain the targets\n",
    "        \n",
    "        if FLAGS['cuda']:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            \n",
    "\n",
    "        # pass image to model\n",
    "        \n",
    "        # no_grad impacts the autograd engine and deactivate it.\n",
    "        # It will reduce memory usage and speed up computations\n",
    "        # but you won’t be able to backprop\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            output_global, fm_global, pool_global = model_global(images)\n",
    "        \n",
    "            patchs_var = Attention_gen_patchs(images.cpu(),fm_global)\n",
    "\n",
    "            output_local, _, pool_local = model_local(patchs_var)\n",
    "\n",
    "            output_fusion = model_fusion(pool_global, pool_local)\n",
    "\n",
    "        # Add the outputs and targets to a list \n",
    "        targets_np = targets.cpu().detach().numpy().tolist()\n",
    "        outputs_g = output_global.cpu().detach().numpy().tolist()\n",
    "        outputs_l = output_local.cpu().detach().numpy().tolist()\n",
    "        outputs_f = output_fusion.cpu().detach().numpy().tolist()\n",
    "        \n",
    "        \n",
    "        fin_targets.extend(targets_np) \n",
    "        \n",
    "        global_outputs.extend(outputs_g)\n",
    "        local_outputs.extend(outputs_l)\n",
    "        fusion_outputs.extend(outputs_f)\n",
    "        \n",
    "        del targets_np, outputs_g, outputs_l, outputs_f\n",
    "        gc.collect() # delete for memory conservation\n",
    "                \n",
    "    og, ol, of, t = np.array(global_outputs), np.array(local_outputs), np.array(fusion_outputs), np.array(fin_targets)\n",
    "    \n",
    "\n",
    "    \n",
    "    # calculate loss\n",
    "    # loss = loss_fn(torch.tensor(o), t)\n",
    "    \n",
    "    AUROCs_g = compute_AUCs(torch.tensor(t), torch.tensor(og))\n",
    "    AUROC_avg = np.array(AUROCs_g).mean()\n",
    "    print('Global branch: The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "    for i in range(N_CLASSES):\n",
    "        print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs_g[i]))\n",
    "    \n",
    "    AUROCs_l = compute_AUCs(torch.tensor(t), torch.tensor(ol))\n",
    "    AUROC_avg = np.array(AUROCs_l).mean()\n",
    "    print('\\n')\n",
    "    print('Local branch: The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "    for i in range(N_CLASSES):\n",
    "        print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs_l[i]))\n",
    "\n",
    "    AUROCs_f = compute_AUCs(torch.tensor(t), torch.tensor(of))\n",
    "    AUROC_avg = np.array(AUROCs_f).mean()\n",
    "    print('\\n')\n",
    "    print('Fusion branch: The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "    for i in range(N_CLASSES):\n",
    "        print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs_f[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== training fold 0 for 10 epochs ==========\n",
      "EPOCH 0:\n",
      "step: 0 totalloss: 0.702 loss1: 0.701 loss2: 0.716 loss3: 0.698\n",
      "step: 500 totalloss: 0.644 loss1: 0.673 loss2: 0.689 loss3: 0.374\n",
      "step: 1000 totalloss: 0.615 loss1: 0.639 loss2: 0.671 loss3: 0.368\n",
      "step: 1500 totalloss: 0.591 loss1: 0.614 loss2: 0.638 loss3: 0.355\n",
      "step: 2000 totalloss: 0.571 loss1: 0.594 loss2: 0.617 loss3: 0.339\n",
      "step: 2500 totalloss: 0.561 loss1: 0.578 loss2: 0.606 loss3: 0.381\n",
      "step: 3000 totalloss: 0.515 loss1: 0.527 loss2: 0.576 loss3: 0.355\n",
      "step: 3500 totalloss: 0.476 loss1: 0.488 loss2: 0.541 loss3: 0.314\n",
      "step: 4000 totalloss: 0.471 loss1: 0.479 loss2: 0.533 loss3: 0.348\n",
      "step: 4500 totalloss: 0.418 loss1: 0.425 loss2: 0.488 loss3: 0.295\n",
      " Epoch over  Loss: 0.53979\n",
      "Global branch: The average AUROC is 0.599\n",
      "The AUROC of Atelectasis is 0.6134365731935525\n",
      "The AUROC of Cardiomegaly is 0.6173702851676385\n",
      "The AUROC of Effusion is 0.661927058683873\n",
      "The AUROC of Infiltration is 0.5764799776570552\n",
      "The AUROC of Mass is 0.579097553063754\n",
      "The AUROC of Nodule is 0.5170380231886724\n",
      "The AUROC of Pneumonia is 0.6179273411354789\n",
      "The AUROC of Pneumothorax is 0.5956785595741907\n",
      "The AUROC of Consolidation is 0.6949148510836578\n",
      "The AUROC of Edema is 0.7080818809005085\n",
      "The AUROC of Emphysema is 0.6212151651945438\n",
      "The AUROC of Fibrosis is 0.4603042032382926\n",
      "The AUROC of Pleural_Thickening is 0.5805795930954336\n",
      "The AUROC of Hernia is 0.5481399028755388\n",
      "\n",
      "\n",
      "Local branch: The average AUROC is 0.510\n",
      "The AUROC of Atelectasis is 0.5060475939242786\n",
      "The AUROC of Cardiomegaly is 0.5420436254859087\n",
      "The AUROC of Effusion is 0.5067205069451928\n",
      "The AUROC of Infiltration is 0.5091768667769592\n",
      "The AUROC of Mass is 0.5201291855488419\n",
      "The AUROC of Nodule is 0.5138314604857285\n",
      "The AUROC of Pneumonia is 0.5145304839288514\n",
      "The AUROC of Pneumothorax is 0.5354121842289319\n",
      "The AUROC of Consolidation is 0.48951325403121854\n",
      "The AUROC of Edema is 0.5712268518518518\n",
      "The AUROC of Emphysema is 0.5033210112924865\n",
      "The AUROC of Fibrosis is 0.4665474567955078\n",
      "The AUROC of Pleural_Thickening is 0.52186792260127\n",
      "The AUROC of Hernia is 0.4410694603590331\n",
      "\n",
      "\n",
      "Fusion branch: The average AUROC is 0.579\n",
      "The AUROC of Atelectasis is 0.5865466901351795\n",
      "The AUROC of Cardiomegaly is 0.5826640700923226\n",
      "The AUROC of Effusion is 0.6222102473029097\n",
      "The AUROC of Infiltration is 0.5588713052413041\n",
      "The AUROC of Mass is 0.5728099248828338\n",
      "The AUROC of Nodule is 0.5248271480923786\n",
      "The AUROC of Pneumonia is 0.5873318141514573\n",
      "The AUROC of Pneumothorax is 0.5655762118140759\n",
      "The AUROC of Consolidation is 0.6394512544604063\n",
      "The AUROC of Edema is 0.7042161401597675\n",
      "The AUROC of Emphysema is 0.5809695221656976\n",
      "The AUROC of Fibrosis is 0.47869268930927333\n",
      "The AUROC of Pleural_Thickening is 0.5859483763877156\n",
      "The AUROC of Hernia is 0.5210367217766138\n",
      "EPOCH 1:\n",
      "step: 0 totalloss: 0.426 loss1: 0.427 loss2: 0.497 loss3: 0.349\n",
      "step: 500 totalloss: 0.357 loss1: 0.358 loss2: 0.438 loss3: 0.273\n",
      "step: 1000 totalloss: 0.347 loss1: 0.346 loss2: 0.424 loss3: 0.283\n",
      "step: 1500 totalloss: 0.285 loss1: 0.281 loss2: 0.379 loss3: 0.228\n",
      "step: 2000 totalloss: 0.342 loss1: 0.337 loss2: 0.410 loss3: 0.312\n",
      "step: 2500 totalloss: 0.277 loss1: 0.270 loss2: 0.350 loss3: 0.257\n",
      "step: 3000 totalloss: 0.289 loss1: 0.279 loss2: 0.370 loss3: 0.288\n",
      "step: 3500 totalloss: 0.243 loss1: 0.236 loss2: 0.304 loss3: 0.231\n",
      "step: 4000 totalloss: 0.240 loss1: 0.231 loss2: 0.302 loss3: 0.251\n",
      "step: 4500 totalloss: 0.163 loss1: 0.152 loss2: 0.246 loss3: 0.165\n",
      " Epoch over  Loss: 0.28416\n",
      "Global branch: The average AUROC is 0.595\n",
      "The AUROC of Atelectasis is 0.6154432478594807\n",
      "The AUROC of Cardiomegaly is 0.6098197202988339\n",
      "The AUROC of Effusion is 0.6762853959441602\n",
      "The AUROC of Infiltration is 0.5874660181370622\n",
      "The AUROC of Mass is 0.5903181191577755\n",
      "The AUROC of Nodule is 0.5172474963609517\n",
      "The AUROC of Pneumonia is 0.6050165565497249\n",
      "The AUROC of Pneumothorax is 0.6062407202425406\n",
      "The AUROC of Consolidation is 0.6721600443017683\n",
      "The AUROC of Edema is 0.650625\n",
      "The AUROC of Emphysema is 0.6002374147473166\n",
      "The AUROC of Fibrosis is 0.47314316087880937\n",
      "The AUROC of Pleural_Thickening is 0.5757859259171119\n",
      "The AUROC of Hernia is 0.5532711300267364\n",
      "\n",
      "\n",
      "Local branch: The average AUROC is 0.545\n",
      "The AUROC of Atelectasis is 0.530671963632833\n",
      "The AUROC of Cardiomegaly is 0.5508258548955296\n",
      "The AUROC of Effusion is 0.5547245365084237\n",
      "The AUROC of Infiltration is 0.5464170379580933\n",
      "The AUROC of Mass is 0.5423012746671702\n",
      "The AUROC of Nodule is 0.5052479837726372\n",
      "The AUROC of Pneumonia is 0.5513955193858507\n",
      "The AUROC of Pneumothorax is 0.5321326883068388\n",
      "The AUROC of Consolidation is 0.5887355259377693\n",
      "The AUROC of Edema is 0.632998139070443\n",
      "The AUROC of Emphysema is 0.5520347090228086\n",
      "The AUROC of Fibrosis is 0.4694046775336641\n",
      "The AUROC of Pleural_Thickening is 0.5276342053283516\n",
      "The AUROC of Hernia is 0.5407748131172587\n",
      "\n",
      "\n",
      "Fusion branch: The average AUROC is 0.582\n",
      "The AUROC of Atelectasis is 0.567341868770159\n",
      "The AUROC of Cardiomegaly is 0.5643064033649173\n",
      "The AUROC of Effusion is 0.6221816377222308\n",
      "The AUROC of Infiltration is 0.5687385023797342\n",
      "The AUROC of Mass is 0.5835236710414503\n",
      "The AUROC of Nodule is 0.5182720917269406\n",
      "The AUROC of Pneumonia is 0.6158758350355723\n",
      "The AUROC of Pneumothorax is 0.5853909945232761\n",
      "The AUROC of Consolidation is 0.654695196339275\n",
      "The AUROC of Edema is 0.6972537672476399\n",
      "The AUROC of Emphysema is 0.5704749692531306\n",
      "The AUROC of Fibrosis is 0.4709750313471079\n",
      "The AUROC of Pleural_Thickening is 0.5827427237895788\n",
      "The AUROC of Hernia is 0.5519397610083483\n",
      "EPOCH 2:\n",
      "step: 0 totalloss: 0.220 loss1: 0.212 loss2: 0.273 loss3: 0.227\n",
      "step: 500 totalloss: 0.162 loss1: 0.150 loss2: 0.239 loss3: 0.177\n",
      "step: 1000 totalloss: 0.219 loss1: 0.213 loss2: 0.250 loss3: 0.234\n",
      "step: 1500 totalloss: 0.206 loss1: 0.199 loss2: 0.248 loss3: 0.220\n",
      "step: 2000 totalloss: 0.149 loss1: 0.141 loss2: 0.193 loss3: 0.169\n",
      "step: 2500 totalloss: 0.176 loss1: 0.172 loss2: 0.195 loss3: 0.187\n",
      "step: 3000 totalloss: 0.182 loss1: 0.177 loss2: 0.199 loss3: 0.210\n",
      "step: 3500 totalloss: 0.184 loss1: 0.179 loss2: 0.202 loss3: 0.209\n",
      "step: 4000 totalloss: 0.154 loss1: 0.151 loss2: 0.168 loss3: 0.163\n",
      "step: 4500 totalloss: 0.250 loss1: 0.247 loss2: 0.254 loss3: 0.276\n",
      " Epoch over  Loss: 0.19684\n",
      "Global branch: The average AUROC is 0.623\n",
      "The AUROC of Atelectasis is 0.6452444354993383\n",
      "The AUROC of Cardiomegaly is 0.6211645484086492\n",
      "The AUROC of Effusion is 0.7207512579825064\n",
      "The AUROC of Infiltration is 0.6007818629938728\n",
      "The AUROC of Mass is 0.5970219269259819\n",
      "The AUROC of Nodule is 0.5477616526087064\n",
      "The AUROC of Pneumonia is 0.6182746860836109\n",
      "The AUROC of Pneumothorax is 0.6577495791694821\n",
      "The AUROC of Consolidation is 0.6962206956208505\n",
      "The AUROC of Edema is 0.6955033587509077\n",
      "The AUROC of Emphysema is 0.6167435483983676\n",
      "The AUROC of Fibrosis is 0.5061894851144693\n",
      "The AUROC of Pleural_Thickening is 0.6089004672322637\n",
      "The AUROC of Hernia is 0.5910918317236864\n",
      "\n",
      "\n",
      "Local branch: The average AUROC is 0.538\n",
      "The AUROC of Atelectasis is 0.5323241678152661\n",
      "The AUROC of Cardiomegaly is 0.5280866587706511\n",
      "The AUROC of Effusion is 0.5522079422157271\n",
      "The AUROC of Infiltration is 0.5536414118982647\n",
      "The AUROC of Mass is 0.5372124855962894\n",
      "The AUROC of Nodule is 0.4919358598223686\n",
      "The AUROC of Pneumonia is 0.5575534297260791\n",
      "The AUROC of Pneumothorax is 0.5453795883862631\n",
      "The AUROC of Consolidation is 0.5839119371349905\n",
      "The AUROC of Edema is 0.6533356027596224\n",
      "The AUROC of Emphysema is 0.535778175313059\n",
      "The AUROC of Fibrosis is 0.46268019074099975\n",
      "The AUROC of Pleural_Thickening is 0.5113353650797428\n",
      "The AUROC of Hernia is 0.49225077754133245\n",
      "\n",
      "\n",
      "Fusion branch: The average AUROC is 0.587\n",
      "The AUROC of Atelectasis is 0.5743182550174832\n",
      "The AUROC of Cardiomegaly is 0.5483655627429543\n",
      "The AUROC of Effusion is 0.6270909825238475\n",
      "The AUROC of Infiltration is 0.5691166972783113\n",
      "The AUROC of Mass is 0.5721775687020684\n",
      "The AUROC of Nodule is 0.5289477615602959\n",
      "The AUROC of Pneumonia is 0.6109787461525782\n",
      "The AUROC of Pneumothorax is 0.6099360456156573\n",
      "The AUROC of Consolidation is 0.6558962537052767\n",
      "The AUROC of Edema is 0.7201141521423384\n",
      "The AUROC of Emphysema is 0.5610436727834303\n",
      "The AUROC of Fibrosis is 0.49675142521038823\n",
      "The AUROC of Pleural_Thickening is 0.5971443005993107\n",
      "The AUROC of Hernia is 0.549113330059475\n",
      "EPOCH 3:\n",
      "step: 0 totalloss: 0.228 loss1: 0.223 loss2: 0.246 loss3: 0.253\n",
      "step: 500 totalloss: 0.215 loss1: 0.213 loss2: 0.216 loss3: 0.235\n",
      "step: 1000 totalloss: 0.270 loss1: 0.269 loss2: 0.271 loss3: 0.278\n",
      "step: 1500 totalloss: 0.234 loss1: 0.228 loss2: 0.247 loss3: 0.266\n",
      "step: 2000 totalloss: 0.163 loss1: 0.160 loss2: 0.163 loss3: 0.192\n",
      "step: 2500 totalloss: 0.164 loss1: 0.162 loss2: 0.169 loss3: 0.178\n",
      "step: 3000 totalloss: 0.128 loss1: 0.124 loss2: 0.142 loss3: 0.151\n",
      "step: 3500 totalloss: 0.267 loss1: 0.261 loss2: 0.278 loss3: 0.305\n",
      "step: 4000 totalloss: 0.182 loss1: 0.178 loss2: 0.183 loss3: 0.214\n",
      "step: 4500 totalloss: 0.175 loss1: 0.172 loss2: 0.175 loss3: 0.199\n",
      " Epoch over  Loss: 0.18308\n",
      "Global branch: The average AUROC is 0.644\n",
      "The AUROC of Atelectasis is 0.6649855649529325\n",
      "The AUROC of Cardiomegaly is 0.6271123739674442\n",
      "The AUROC of Effusion is 0.7439512845176937\n",
      "The AUROC of Infiltration is 0.6118907861285391\n",
      "The AUROC of Mass is 0.6084150693985458\n",
      "The AUROC of Nodule is 0.5639513209887503\n",
      "The AUROC of Pneumonia is 0.6248152185932665\n",
      "The AUROC of Pneumothorax is 0.6864800601906185\n",
      "The AUROC of Consolidation is 0.7135752781151797\n",
      "The AUROC of Edema is 0.7139960058097313\n",
      "The AUROC of Emphysema is 0.6378193481663685\n",
      "The AUROC of Fibrosis is 0.5463959003434552\n",
      "The AUROC of Pleural_Thickening is 0.6425224493600346\n",
      "The AUROC of Hernia is 0.6280482348447645\n",
      "\n",
      "\n",
      "Local branch: The average AUROC is 0.564\n",
      "The AUROC of Atelectasis is 0.5532770464297918\n",
      "The AUROC of Cardiomegaly is 0.5246484754616133\n",
      "The AUROC of Effusion is 0.581362542851401\n",
      "The AUROC of Infiltration is 0.5630950918712845\n",
      "The AUROC of Mass is 0.568935284675668\n",
      "The AUROC of Nodule is 0.5320528570894476\n",
      "The AUROC of Pneumonia is 0.523217838876719\n",
      "The AUROC of Pneumothorax is 0.5539444711168012\n",
      "The AUROC of Consolidation is 0.6184617666543477\n",
      "The AUROC of Edema is 0.6683065541031228\n",
      "The AUROC of Emphysema is 0.5428220035778175\n",
      "The AUROC of Fibrosis is 0.5051594613749114\n",
      "The AUROC of Pleural_Thickening is 0.5518007331738873\n",
      "The AUROC of Hernia is 0.6100027282152016\n",
      "\n",
      "\n",
      "Fusion branch: The average AUROC is 0.615\n",
      "The AUROC of Atelectasis is 0.606675170417991\n",
      "The AUROC of Cardiomegaly is 0.5669969327016521\n",
      "The AUROC of Effusion is 0.6706658576035994\n",
      "The AUROC of Infiltration is 0.579583379301807\n",
      "The AUROC of Mass is 0.6012304787083372\n",
      "The AUROC of Nodule is 0.5498309213788644\n",
      "The AUROC of Pneumonia is 0.625317240588614\n",
      "The AUROC of Pneumothorax is 0.641910829865927\n",
      "The AUROC of Consolidation is 0.6792498062318657\n",
      "The AUROC of Edema is 0.716480119825708\n",
      "The AUROC of Emphysema is 0.5796579760174418\n",
      "The AUROC of Fibrosis is 0.5230155917788802\n",
      "The AUROC of Pleural_Thickening is 0.6263540018165737\n",
      "The AUROC of Hernia is 0.6407508048234845\n",
      "EPOCH 4:\n",
      "step: 0 totalloss: 0.175 loss1: 0.170 loss2: 0.184 loss3: 0.213\n",
      "step: 500 totalloss: 0.190 loss1: 0.186 loss2: 0.199 loss3: 0.218\n",
      "step: 1000 totalloss: 0.156 loss1: 0.150 loss2: 0.163 loss3: 0.190\n",
      "step: 1500 totalloss: 0.316 loss1: 0.316 loss2: 0.310 loss3: 0.326\n",
      "step: 2000 totalloss: 0.223 loss1: 0.215 loss2: 0.233 loss3: 0.276\n",
      "step: 2500 totalloss: 0.221 loss1: 0.214 loss2: 0.228 loss3: 0.273\n",
      "step: 3000 totalloss: 0.176 loss1: 0.171 loss2: 0.186 loss3: 0.203\n",
      "step: 3500 totalloss: 0.210 loss1: 0.203 loss2: 0.222 loss3: 0.255\n",
      "step: 4000 totalloss: 0.135 loss1: 0.131 loss2: 0.141 loss3: 0.158\n",
      "step: 4500 totalloss: 0.147 loss1: 0.144 loss2: 0.146 loss3: 0.170\n",
      " Epoch over  Loss: 0.17968\n",
      "Global branch: The average AUROC is 0.657\n",
      "The AUROC of Atelectasis is 0.6747398314986278\n",
      "The AUROC of Cardiomegaly is 0.6246510867340346\n",
      "The AUROC of Effusion is 0.7559853041888525\n",
      "The AUROC of Infiltration is 0.6208651077214478\n",
      "The AUROC of Mass is 0.6197014625031005\n",
      "The AUROC of Nodule is 0.5793493300166364\n",
      "The AUROC of Pneumonia is 0.6323502973801913\n",
      "The AUROC of Pneumothorax is 0.711175791576277\n",
      "The AUROC of Consolidation is 0.7305933064358312\n",
      "The AUROC of Edema is 0.7311705700798838\n",
      "The AUROC of Emphysema is 0.6516884136711762\n",
      "The AUROC of Fibrosis is 0.567531483399662\n",
      "The AUROC of Pleural_Thickening is 0.6565505725380072\n",
      "The AUROC of Hernia is 0.6382081082555792\n",
      "\n",
      "\n",
      "Local branch: The average AUROC is 0.565\n",
      "The AUROC of Atelectasis is 0.551444022472632\n",
      "The AUROC of Cardiomegaly is 0.5748342959775536\n",
      "The AUROC of Effusion is 0.5928804531273475\n",
      "The AUROC of Infiltration is 0.5700708829822043\n",
      "The AUROC of Mass is 0.565402074327833\n",
      "The AUROC of Nodule is 0.5295334863982446\n",
      "The AUROC of Pneumonia is 0.5296216721538576\n",
      "The AUROC of Pneumothorax is 0.573670623807153\n",
      "The AUROC of Consolidation is 0.6105125098367413\n",
      "The AUROC of Edema is 0.6468979212055193\n",
      "The AUROC of Emphysema is 0.5481612149206172\n",
      "The AUROC of Fibrosis is 0.4796947064275201\n",
      "The AUROC of Pleural_Thickening is 0.5445139872205232\n",
      "The AUROC of Hernia is 0.5917662465215255\n",
      "\n",
      "\n",
      "Fusion branch: The average AUROC is 0.624\n",
      "The AUROC of Atelectasis is 0.6233439125735062\n",
      "The AUROC of Cardiomegaly is 0.5990503917853344\n",
      "The AUROC of Effusion is 0.6821924698601245\n",
      "The AUROC of Infiltration is 0.5850158962440303\n",
      "The AUROC of Mass is 0.6064192729109247\n",
      "The AUROC of Nodule is 0.5567305353420398\n",
      "The AUROC of Pneumonia is 0.6193977906961756\n",
      "The AUROC of Pneumothorax is 0.6631147978235358\n",
      "The AUROC of Consolidation is 0.6813878444941313\n",
      "The AUROC of Edema is 0.7225408496732026\n",
      "The AUROC of Emphysema is 0.6068353260565743\n",
      "The AUROC of Fibrosis is 0.5303440004361337\n",
      "The AUROC of Pleural_Thickening is 0.6322164677558175\n",
      "The AUROC of Hernia is 0.626376384569215\n",
      "EPOCH 5:\n",
      "step: 0 totalloss: 0.096 loss1: 0.092 loss2: 0.097 loss3: 0.120\n",
      "step: 500 totalloss: 0.188 loss1: 0.186 loss2: 0.185 loss3: 0.209\n",
      "step: 1000 totalloss: 0.126 loss1: 0.121 loss2: 0.136 loss3: 0.157\n"
     ]
    }
   ],
   "source": [
    "MX_global = TimmModels(FLAGS['model'],pretrained=FLAGS['pretrained'], num_classes=14)\n",
    "MX_local = TimmModels(FLAGS['model'],pretrained=FLAGS['pretrained'], num_classes=14)\n",
    "\n",
    "Global_Branch_model = MX_global.to(device) # put model onto the current GPU\n",
    "Local_Branch_model = MX_local.to(device) # put model onto the current GPU\n",
    "Fusion_Branch_model = Fusion_Branch(input_size = 4096, output_size = N_CLASSES).to(device)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "optimizer_global = Adam(Global_Branch_model.parameters(), lr=FLAGS['lr'])\n",
    "optimizer_local = Adam(Local_Branch_model.parameters(), lr=FLAGS['lr'])\n",
    "optimizer_fusion = Adam(Fusion_Branch_model.parameters(), lr=FLAGS['lr_f'])\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader)*FLAGS['epochs']) #let's use a scheduler\n",
    "\n",
    "lr_scheduler_global = lr_scheduler.StepLR(optimizer_global , step_size = 10, gamma = 1)\n",
    "lr_scheduler_local = lr_scheduler.StepLR(optimizer_local , step_size = 10, gamma = 1)\n",
    "lr_scheduler_fusion = lr_scheduler.StepLR(optimizer_fusion , step_size = 15, gamma = 0.1)\n",
    "\n",
    "print(f'========== training fold {FLAGS[\"fold\"]} for {FLAGS[\"epochs\"]} epochs ==========')\n",
    "for i in range(FLAGS['epochs']):\n",
    "    print(f'EPOCH {i}:')\n",
    "    # train one epoch\n",
    "    train_with_attn(train_loader, loss_fn,  Global_Branch_model,Local_Branch_model, Fusion_Branch_model, optimizer_global, optimizer_local, optimizer_fusion, lr_scheduler_global, lr_scheduler_local, lr_scheduler_fusion, device,   i)\n",
    "\n",
    "    # validation one epoch\n",
    "    eval_with_attn(valid_loader, loss_fn, Global_Branch_model, Local_Branch_model, Fusion_Branch_model, device)\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "    torch.save(Global_Branch_model.state_dict(), f'densenet_attn_NIH_{FLAGS[\"epochs\"]}_'+str(i)+'_global.pth')\n",
    "    torch.save(Local_Branch_model.state_dict(), f'densenet_attn_NIH_{FLAGS[\"epochs\"]}_'+str(i)+'_local.pth')\n",
    "    torch.save(Fusion_Branch_model.state_dict(), f'densenet_attn_NIH_{FLAGS[\"epochs\"]}_'+str(i)+'_fusion.pth')\n",
    "\n",
    "print('Saving model...')\n",
    "\n",
    "torch.save(Global_Branch_model.state_dict(), f'densenet_attn_NIH_{FLAGS[\"epochs\"]}_global.pth')\n",
    "torch.save(Local_Branch_model.state_dict(), f'densenet_attn_NIH_{FLAGS[\"epochs\"]}_local.pth')\n",
    "torch.save(Fusion_Branch_model.state_dict(), f'densenet_attn_NIH_{FLAGS[\"epochs\"]}_fusion.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
